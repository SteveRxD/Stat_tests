<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 4 Correlations | Statistical tests as linear models</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 4 Correlations | Statistical tests as linear models" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Correlations | Statistical tests as linear models" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Steve Doogue">


<meta name="date" content="2019-06-05">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="linearmodel.html">
<link rel="next" href="one-mean.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical tests as linear models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>2</b> The data</a><ul>
<li class="chapter" data-level="2.1" data-path="data.html"><a href="data.html#samplevalues"><i class="fa fa-check"></i><b>2.1</b> Sample values</a></li>
<li class="chapter" data-level="2.2" data-path="data.html"><a href="data.html#ranktrans"><i class="fa fa-check"></i><b>2.2</b> ‘Signed rank’ values</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linearmodel.html"><a href="linearmodel.html"><i class="fa fa-check"></i><b>3</b> The linear model</a><ul>
<li class="chapter" data-level="3.1" data-path="linearmodel.html"><a href="linearmodel.html#overview-of-the-linear-model"><i class="fa fa-check"></i><b>3.1</b> Overview of the linear model</a></li>
<li class="chapter" data-level="3.2" data-path="linearmodel.html"><a href="linearmodel.html#estimating-linear-models-in-r"><i class="fa fa-check"></i><b>3.2</b> Estimating linear models in R</a></li>
<li class="chapter" data-level="3.3" data-path="linearmodel.html"><a href="linearmodel.html#assumptions"><i class="fa fa-check"></i><b>3.3</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="correlations.html"><a href="correlations.html"><i class="fa fa-check"></i><b>4</b> Correlations</a><ul>
<li class="chapter" data-level="4.1" data-path="correlations.html"><a href="correlations.html#pearson-correlation"><i class="fa fa-check"></i><b>4.1</b> Pearson correlation</a></li>
<li class="chapter" data-level="4.2" data-path="correlations.html"><a href="correlations.html#spearman-correlation"><i class="fa fa-check"></i><b>4.2</b> Spearman correlation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="one-mean.html"><a href="one-mean.html"><i class="fa fa-check"></i><b>5</b> One mean</a><ul>
<li class="chapter" data-level="5.1" data-path="one-mean.html"><a href="one-mean.html#one-sample"><i class="fa fa-check"></i><b>5.1</b> One sample</a><ul>
<li class="chapter" data-level="5.1.1" data-path="one-mean.html"><a href="one-mean.html#one-sample-t-test"><i class="fa fa-check"></i><b>5.1.1</b> One-sample t-test</a></li>
<li class="chapter" data-level="5.1.2" data-path="one-mean.html"><a href="one-mean.html#wilcoxen-signed-rank"><i class="fa fa-check"></i><b>5.1.2</b> Wilcoxen signed-rank</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="one-mean.html"><a href="one-mean.html#paired-samples"><i class="fa fa-check"></i><b>5.2</b> Paired samples</a><ul>
<li class="chapter" data-level="5.2.1" data-path="one-mean.html"><a href="one-mean.html#paired-sample-t-test"><i class="fa fa-check"></i><b>5.2.1</b> Paired-sample t-test</a></li>
<li class="chapter" data-level="5.2.2" data-path="one-mean.html"><a href="one-mean.html#wilcoxen-matched-pairs"><i class="fa fa-check"></i><b>5.2.2</b> Wilcoxen matched pairs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html"><i class="fa fa-check"></i><b>6</b> Two means (independent samples)</a><ul>
<li class="chapter" data-level="6.1" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#independent-sample-t-test"><i class="fa fa-check"></i><b>6.1</b> Independent-sample t-test</a></li>
<li class="chapter" data-level="6.2" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#welchs-t-test"><i class="fa fa-check"></i><b>6.2</b> Welch’s t-test</a></li>
<li class="chapter" data-level="6.3" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#mann-whitney-u-test"><i class="fa fa-check"></i><b>6.3</b> Mann-Whitney U test</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="three-or-more-means.html"><a href="three-or-more-means.html"><i class="fa fa-check"></i><b>7</b> Three or more means</a><ul>
<li class="chapter" data-level="7.1" data-path="three-or-more-means.html"><a href="three-or-more-means.html#one-way-anova"><i class="fa fa-check"></i><b>7.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="7.2" data-path="three-or-more-means.html"><a href="three-or-more-means.html#two-way-anova"><i class="fa fa-check"></i><b>7.2</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="7.3" data-path="three-or-more-means.html"><a href="three-or-more-means.html#ancova"><i class="fa fa-check"></i><b>7.3</b> ANCOVA</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="appendixtypes.html"><a href="appendixtypes.html"><i class="fa fa-check"></i><b>8</b> Appendix - Types of variables</a><ul>
<li class="chapter" data-level="8.1" data-path="appendixtypes.html"><a href="appendixtypes.html#discrete-variables"><i class="fa fa-check"></i><b>8.1</b> Discrete variables</a></li>
<li class="chapter" data-level="8.2" data-path="appendixtypes.html"><a href="appendixtypes.html#continuous-variables"><i class="fa fa-check"></i><b>8.2</b> Continuous variables</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical tests as linear models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="correlations" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Correlations</h1>
<p>Correlation is a measure of the strength and direction of association that exists between two variables. Correlation coefficents (<span class="math inline">\(r\)</span>) assume values in the range from −1 to +1, where ±1 indicates the strongest possible positive or negative correlation and 0 indicates no linear association between the variables.</p>
<div id="pearson-correlation" class="section level2">
<h2><span class="header-section-number">4.1</span> Pearson correlation</h2>
<p>We start by looking at the Pearson correlation coefficient. Here we compare the built-in test (in R) for the Pearson correlation with the equivalant linear model.</p>
<p>The equivalent linear model is the basic regression of <span class="math inline">\(y\)</span> on <span class="math inline">\(x\)</span>, specified as follows: <span class="math inline">\(y = \beta_0 + \beta_1x \qquad H_0: \beta_1 = 0\)</span></p>
<p>The two tests are written using the following R code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Pearson (built-in test)</span>
<span class="kw">cor.test</span>(y, x, <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>) 
<span class="co"># Linear model</span>
<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">digits =</span> <span class="dv">5</span>)</code></pre></div>
<p>If you were to run the code above, you would see the following the key statistics found in the output of each test:</p>
<table>
<caption><span id="tab:unnamed-chunk-14">Table 4.1: </span>Pearson vs linear model</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="left">r</th>
<th align="left">slope</th>
<th align="right">t</th>
<th align="right">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">cor.test (Pearson)</td>
<td align="left">-0.2318</td>
<td align="left"></td>
<td align="right">-1.6507</td>
<td align="right">0.1053</td>
</tr>
<tr class="even">
<td align="left">lm</td>
<td align="left"></td>
<td align="left">-0.4636</td>
<td align="right">-1.6507</td>
<td align="right">0.1053</td>
</tr>
</tbody>
</table>
<p>The output shows that the correlation coefficient (<span class="math inline">\(r\)</span>) has a t-statistic of -1.6507 and p-value of 0.1053. And the exact same results are found in the linear model!</p>
<p>The difference is that the linear model returns the <em>slope</em> of the relationship, <span class="math inline">\(\beta_1\)</span> (which in this case is -0.4636), rather than the correlation coefficient, <span class="math inline">\(r\)</span>. The slope is usually much more interpretable and informative than the correlation coefficient. However it is useful to understand how the two are related, which is by the following formula:</p>
<p><span class="math inline">\(\beta_1 = r \cdot sd_y / sd_x\)</span></p>
<p>This shows that:</p>
<ul>
<li>When both <code>x</code> and <code>y</code> have the same standard deviations (<span class="math inline">\(sd_x\)</span> and <span class="math inline">\(sd_y\)</span>) then the slope (<span class="math inline">\(\beta_1\)</span>) will be equal the correlation coefficient (<span class="math inline">\(r\)</span>)</li>
<li>The ratio of the slope to the correlation coefficient (<span class="math inline">\(\beta_1 / r\)</span>) is equal to the ratio of the standard deviations (<span class="math inline">\(sd_y / sd_x\)</span>). We know that when we set up our data in Section <a href="data.html#samplevalues">2.1</a> that the standard deviation of <code>y</code> was twice as large as <code>x</code>. This is why the value of the slope (-0.4636) is twice the size of the correlation coefficient (-0.2318),</li>
<li>The slope from the linear model will always have the same sign (+ or -) as the correlation coefficient (as standard devaiations are always positive).</li>
</ul>
</div>
<div id="spearman-correlation" class="section level2">
<h2><span class="header-section-number">4.2</span> Spearman correlation</h2>
<p>There will be times when it is more appropriate to use the <strong>Spearman rank correlation</strong> than the Pearson correlation. This could be the case when:</p>
<ol style="list-style-type: decimal">
<li>The relationship between the variables is not linear, i.e. not a straight line;</li>
<li>The data is not normally distributed;<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></li>
<li>The data has large outliers; or</li>
<li>When you are working with ordinal rather than continuous data.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></li>
</ol>
<p>The Spearman correlation is a <em>non-parameteric</em> test as it does not require that the parameters of the linear model hold true - for example, there does not need to be a linear relationship between the two variables, and the data does not need to be normally distributed.</p>
<p>The Spearman rank correlation is the same as a Pearson correlation but using the <em>rank</em> of the values in our samples. This is an approximation only, which Lindelov shows is approximate when the sample is greater than 10 and almost perfect when the sample is greater than 20.</p>
<p>This is also the same as the linear model using rank-transformed values of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>:</p>
<p><span class="math inline">\(rank(y) = \beta_0 + \beta_1 \cdot rank(x) \qquad H_0: \beta_1 = 0\)</span></p>
<p>For a comparison of the Spearman test, the Pearson test (using ranks) and the linear model (also using ranks) we run the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Spearman</span>
<span class="kw">cor.test</span>(y, x, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>)

<span class="co"># Pearson using ranks</span>
<span class="kw">cor.test</span>(<span class="kw">rank</span>(y), <span class="kw">rank</span>(x), <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>)

<span class="co"># Linear model using rank</span>
lm &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">rank</span>(y) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">rank</span>(x)) 
  lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">digits =</span> <span class="dv">5</span>) <span class="co"># show summary ouput</span></code></pre></div>
<p>The output of this code is as follows:</p>
<table>
<caption><span id="tab:unnamed-chunk-16">Table 4.2: </span>Spearman, Pearson (ranks) and linear model (ranks)</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="left">correlation</th>
<th align="left">slope</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">cor.test (Spearman)</td>
<td align="left">-0.2266</td>
<td align="left"></td>
<td align="right">0.1135</td>
</tr>
<tr class="even">
<td align="left">cor.test (Pearson with ranks)</td>
<td align="left">-0.2266</td>
<td align="left"></td>
<td align="right">0.1135</td>
</tr>
<tr class="odd">
<td align="left">lm (with ranks)</td>
<td align="left"></td>
<td align="left">-0.2266</td>
<td align="right">0.1135</td>
</tr>
</tbody>
</table>
<p>This shows that the results are all the same (or at least very close approximations). Note that the slope from the linear model has an intuitive interpretation, which is the number of ranks <span class="math inline">\(y\)</span> changes for each rank on <span class="math inline">\(x\)</span>.</p>
<p>Given the similarity of these tests, Lindelov notes that:</p>
<blockquote>
<p>One interesting implication is that many “non-parametric tests” are about as parametric as their parametric counterparts with means, standard deviations, homogeneity of variance, etc. - just on rank-transformed data.</p>
</blockquote>
<p>Finally, the figure below (reproduced from the original book) illustrates how the Pearson and Spearman correlations are the same as linear models, with the latter being based on rank-transformed values.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-17"></span>
<img src="images/correlations.png" alt="Pearson and Spearman correlations as linear models" width="80%" />
<p class="caption">
Figure 4.1: Pearson and Spearman correlations as linear models
</p>
</div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Technically the variables should have <em>bivariate</em> normality, which means they are normally distrbuted when added together, but this is complex and so it is common just to assess whether the variables are individually normal <a href="https://statistics.laerd.com/spss-tutorials/pearsons-product-moment-correlation-using-spss-statistics.php">(source)</a>. If bivariate normality does not hold then you will still get a fair estimate of <span class="math inline">\(r\)</span>, but the inferential tests (t-statistics and p-values) could be misleading <a href="https://www.researchgate.net/post/Why_should_data_be_normally_distributed_and_continuous_in_order_to_apply_Pearson_correlation">(source)</a>.<a href="correlations.html#fnref1">↩</a></p></li>
<li id="fn2"><p>see Chapter <a href="appendixtypes.html#appendixtypes">8</a> for a description of the different types of data.<a href="correlations.html#fnref2">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linearmodel.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="one-mean.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["stat_tests.pdf", "stat_tests.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
