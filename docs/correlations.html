<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 4 Correlations | Common statistical tests are linear models: a work through</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 4 Correlations | Common statistical tests are linear models: a work through" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Correlations | Common statistical tests are linear models: a work through" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Steve Doogue">


<meta name="date" content="2019-07-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="linearmodel.html">
<link rel="next" href="one-mean.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical tests as linear models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>2</b> The data</a><ul>
<li class="chapter" data-level="2.1" data-path="data.html"><a href="data.html#samplevalues"><i class="fa fa-check"></i><b>2.1</b> Sample values</a></li>
<li class="chapter" data-level="2.2" data-path="data.html"><a href="data.html#ranktrans"><i class="fa fa-check"></i><b>2.2</b> ‘Signed rank’ values</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linearmodel.html"><a href="linearmodel.html"><i class="fa fa-check"></i><b>3</b> The linear model</a><ul>
<li class="chapter" data-level="3.1" data-path="linearmodel.html"><a href="linearmodel.html#overview-of-the-linear-model"><i class="fa fa-check"></i><b>3.1</b> Overview of the linear model</a></li>
<li class="chapter" data-level="3.2" data-path="linearmodel.html"><a href="linearmodel.html#estimating-linear-models-in-r"><i class="fa fa-check"></i><b>3.2</b> Estimating linear models in R</a></li>
<li class="chapter" data-level="3.3" data-path="linearmodel.html"><a href="linearmodel.html#assumptions"><i class="fa fa-check"></i><b>3.3</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="correlations.html"><a href="correlations.html"><i class="fa fa-check"></i><b>4</b> Correlations</a><ul>
<li class="chapter" data-level="4.1" data-path="correlations.html"><a href="correlations.html#pearson-correlation"><i class="fa fa-check"></i><b>4.1</b> Pearson correlation</a></li>
<li class="chapter" data-level="4.2" data-path="correlations.html"><a href="correlations.html#spearman-correlation"><i class="fa fa-check"></i><b>4.2</b> Spearman correlation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="one-mean.html"><a href="one-mean.html"><i class="fa fa-check"></i><b>5</b> One mean</a><ul>
<li class="chapter" data-level="5.1" data-path="one-mean.html"><a href="one-mean.html#one-sample"><i class="fa fa-check"></i><b>5.1</b> One sample</a><ul>
<li class="chapter" data-level="5.1.1" data-path="one-mean.html"><a href="one-mean.html#one-sample-t-test"><i class="fa fa-check"></i><b>5.1.1</b> One-sample t-test</a></li>
<li class="chapter" data-level="5.1.2" data-path="one-mean.html"><a href="one-mean.html#wilcoxen-signed-rank"><i class="fa fa-check"></i><b>5.1.2</b> Wilcoxen signed-rank</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="one-mean.html"><a href="one-mean.html#paired-samples"><i class="fa fa-check"></i><b>5.2</b> Paired samples</a><ul>
<li class="chapter" data-level="5.2.1" data-path="one-mean.html"><a href="one-mean.html#paired-sample-t-test"><i class="fa fa-check"></i><b>5.2.1</b> Paired-sample t-test</a></li>
<li class="chapter" data-level="5.2.2" data-path="one-mean.html"><a href="one-mean.html#wilcoxen-matched-pairs"><i class="fa fa-check"></i><b>5.2.2</b> Wilcoxen matched pairs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html"><i class="fa fa-check"></i><b>6</b> Two means (independent samples)</a><ul>
<li class="chapter" data-level="6.1" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#independent-t-test"><i class="fa fa-check"></i><b>6.1</b> Independent t-test</a></li>
<li class="chapter" data-level="6.2" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#welchs-t-test"><i class="fa fa-check"></i><b>6.2</b> Welch’s t-test</a></li>
<li class="chapter" data-level="6.3" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#mann-whitney-u-test"><i class="fa fa-check"></i><b>6.3</b> Mann-Whitney U test</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="three-or-more-means.html"><a href="three-or-more-means.html"><i class="fa fa-check"></i><b>7</b> Three or more means</a><ul>
<li class="chapter" data-level="7.1" data-path="three-or-more-means.html"><a href="three-or-more-means.html#one-way-anova"><i class="fa fa-check"></i><b>7.1</b> One-way ANOVA</a><ul>
<li class="chapter" data-level="7.1.1" data-path="three-or-more-means.html"><a href="three-or-more-means.html#kruskal-wallis"><i class="fa fa-check"></i><b>7.1.1</b> Kruskal-Wallis</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="three-or-more-means.html"><a href="three-or-more-means.html#two-way-anova"><i class="fa fa-check"></i><b>7.2</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="7.3" data-path="three-or-more-means.html"><a href="three-or-more-means.html#ancova"><i class="fa fa-check"></i><b>7.3</b> ANCOVA</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="proportions-and-chi-squared.html"><a href="proportions-and-chi-squared.html"><i class="fa fa-check"></i><b>8</b> Proportions and chi squared</a><ul>
<li class="chapter" data-level="8.1" data-path="proportions-and-chi-squared.html"><a href="proportions-and-chi-squared.html#goodness-of-fit"><i class="fa fa-check"></i><b>8.1</b> Goodness of fit</a></li>
<li class="chapter" data-level="8.2" data-path="proportions-and-chi-squared.html"><a href="proportions-and-chi-squared.html#contingency-tables"><i class="fa fa-check"></i><b>8.2</b> Contingency tables</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="appendixtypes.html"><a href="appendixtypes.html"><i class="fa fa-check"></i><b>9</b> Appendix - Types of variables</a><ul>
<li class="chapter" data-level="9.1" data-path="appendixtypes.html"><a href="appendixtypes.html#discrete-variables"><i class="fa fa-check"></i><b>9.1</b> Discrete variables</a></li>
<li class="chapter" data-level="9.2" data-path="appendixtypes.html"><a href="appendixtypes.html#continuous-variables"><i class="fa fa-check"></i><b>9.2</b> Continuous variables</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Common statistical tests are linear models: a work through</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="correlations" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Correlations</h1>
<p>Correlation is a measure of the strength and direction of association that exists between two variables. Correlation coefficients (<span class="math inline">\(r\)</span>) assume values in the range from −1 to +1, where ±1 indicates the strongest possible positive or negative correlation and 0 indicates no linear association between the variables.</p>
<div id="pearson-correlation" class="section level2">
<h2><span class="header-section-number">4.1</span> Pearson correlation</h2>
<p>We start by looking at the Pearson correlation coefficient. Here we compare the built-in test (in R) for the Pearson correlation with the equivalent linear model.</p>
<p>The equivalent linear model is the basic regression of <span class="math inline">\(y\)</span> on <span class="math inline">\(x\)</span>, specified as follows: <span class="math inline">\(y = \beta_0 + \beta_1x \qquad H_0: \beta_1 = 0\)</span></p>
<p>The two tests are written using the following R code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Pearson (built-in test)</span>
<span class="kw">cor.test</span>(y, x, <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>) 
<span class="co"># Linear model</span>
<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">digits =</span> <span class="dv">8</span>)</code></pre></div>
<p>If you were to run the code above, you would see the following the key statistics found in the output of each test:</p>
<table>
<caption><span id="tab:unnamed-chunk-14">Table 4.1: </span>Pearson vs linear model</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="left">r</th>
<th align="left">slope</th>
<th align="right">t</th>
<th align="right">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">cor.test (Pearson)</td>
<td align="left">-0.2318</td>
<td align="left"></td>
<td align="right">-1.6507</td>
<td align="right">0.1053</td>
</tr>
<tr class="even">
<td align="left">lm</td>
<td align="left"></td>
<td align="left">-0.4636</td>
<td align="right">-1.6507</td>
<td align="right">0.1053</td>
</tr>
</tbody>
</table>
<p>The output shows that the correlation coefficient (<span class="math inline">\(r\)</span>) has a p-value of 0.1053, which is exactly the same as the p-value for the slope of the linear model. In this case, we would not reject the null hypothesis that there was no correlation between the two variables (at the 0.05 level of significance).</p>
<p>The main difference is that the linear model returns the <em>slope</em> of the relationship, <span class="math inline">\(\beta_1\)</span> (which in this case is -0.4636), rather than the correlation coefficient, <span class="math inline">\(r\)</span>. The slope is usually much more interpretable and informative than the correlation coefficient.</p>
<p><strong>Additional note (optional):</strong></p>
<p>It may be useful to understand how the Pearson correlation coefficient (<span class="math inline">\(r\)</span>) and the regression coefficient or slope (<span class="math inline">\(\beta_1\)</span>) are related, which is by the following formula:</p>
<p><span class="math inline">\(\beta_1 = r \cdot sd_y / sd_x\)</span></p>
<p>This shows that:</p>
<ul>
<li>When both <code>x</code> and <code>y</code> have the same standard deviations (<span class="math inline">\(sd_x\)</span> and <span class="math inline">\(sd_y\)</span>) then the slope (<span class="math inline">\(\beta_1\)</span>) will be equal to the correlation coefficient (<span class="math inline">\(r\)</span>)</li>
<li>The ratio of the slope to the correlation coefficient (<span class="math inline">\(\beta_1 / r\)</span>) is equal to the ratio of the standard deviations (<span class="math inline">\(sd_y / sd_x\)</span>). In this example, the standard deviation of <code>y</code> is exactly twice as large as <code>x</code>, which is why the slope has twice the magnitude of the correlation coefficient.</li>
<li>The slope from the linear model will always have the same sign (+ or -) as the correlation coefficient (as standard deviations are always positive).</li>
</ul>
</div>
<div id="spearman-correlation" class="section level2">
<h2><span class="header-section-number">4.2</span> Spearman correlation</h2>
<p>There will be times when it is more appropriate to use the <strong>Spearman rank correlation</strong> than the Pearson correlation. This could be the case when:</p>
<ol style="list-style-type: decimal">
<li>The relationship between the variables is not linear, i.e. not a straight line;</li>
<li>The data is not normally distributed;<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></li>
<li>The data has large outliers; or</li>
<li>When you are working with ordinal rather than continuous data.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></li>
</ol>
<p>The Spearman correlation is a <em>non-parameteric</em> test as it does not require that the parameters of the linear model hold true. For example, there does not need to be a linear relationship between the two variables, and the data does not need to be normally distributed.</p>
<p>The Spearman rank correlation is the same as a Pearson correlation but using the <em>rank</em> of the values in our samples. This is an approximation only, which Lindeløv shows is approximate when the sample size is greater than 10 and almost perfect when the sample is greater than 20.</p>
<p>This is also the same as the linear model using rank-transformed values of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>:</p>
<p><span class="math inline">\(rank(y) = \beta_0 + \beta_1 \cdot rank(x) \qquad H_0: \beta_1 = 0\)</span></p>
<p>For a comparison of the Spearman test, the Pearson test (using ranks) and the linear model (also using ranks) we run the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Spearman</span>
<span class="kw">cor.test</span>(y, x, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>)

<span class="co"># Pearson using ranks</span>
<span class="kw">cor.test</span>(<span class="kw">rank</span>(y), <span class="kw">rank</span>(x), <span class="dt">method =</span> <span class="st">&quot;pearson&quot;</span>)

<span class="co"># Linear model using rank</span>
lm &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">rank</span>(y) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">rank</span>(x)) 
  lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">digits =</span> <span class="dv">5</span>) <span class="co"># show summary ouput</span></code></pre></div>
<p>The output of this code is as follows:</p>
<table>
<caption><span id="tab:unnamed-chunk-16">Table 4.2: </span>Spearman, Pearson (ranks) and linear model (ranks)</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="left">correlation</th>
<th align="left">slope</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">cor.test (Spearman)</td>
<td align="left">-0.2266</td>
<td align="left"></td>
<td align="right">0.1135</td>
</tr>
<tr class="even">
<td align="left">cor.test (Pearson with ranks)</td>
<td align="left">-0.2266</td>
<td align="left"></td>
<td align="right">0.1135</td>
</tr>
<tr class="odd">
<td align="left">lm (with ranks)</td>
<td align="left"></td>
<td align="left">-0.2266</td>
<td align="right">0.1135</td>
</tr>
</tbody>
</table>
<p>This shows that the results are all the same (or at least very close approximations). When ranks are used, the slope of the linear model (<span class="math inline">\(\beta_1\)</span>) has the same value as the correlation coefficient (<span class="math inline">\(r\)</span>). Note that the slope from the linear model has an intuitive interpretation, which is the number of ranks <span class="math inline">\(y\)</span> changes for each change in rank of <span class="math inline">\(x\)</span>.</p>
<p>Given the similarity of these tests, Lindeløv notes that:</p>
<blockquote>
<p>One interesting implication is that many “non-parametric tests” are about as parametric as their parametric counterparts with means, standard deviations, homogeneity of variance, etc. - just on rank-transformed data.</p>
</blockquote>
<p>Finally, the figure below (reproduced from the original book) illustrates how the Pearson and Spearman correlations are equivalent to linear models, with the latter being based on rank-transformed values.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-17"></span>
<img src="images/correlations.png" alt="Pearson and Spearman correlations as linear models" width="80%" />
<p class="caption">
Figure 4.1: Pearson and Spearman correlations as linear models
</p>
</div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>Technically the variables should have <em>bivariate</em> normality, which means they are normally distributed when added together, but this is complex and so it is common just to assess whether the variables are individually normal (explained here on the <a href="https://statistics.laerd.com/spss-tutorials/pearsons-product-moment-correlation-using-spss-statistics.php">Laerd</a> website). If bi-variate normality does not hold then you will still get a fair estimate of <span class="math inline">\(r\)</span>, but the inferential tests (t-statistics and p-values) could be misleading (explained <a href="https://www.researchgate.net/post/Why_should_data_be_normally_distributed_and_continuous_in_order_to_apply_Pearson_correlation">here</a>).<a href="correlations.html#fnref2">↩</a></p></li>
<li id="fn3"><p>see Chapter <a href="appendixtypes.html#appendixtypes">9</a> for a description of the different types of data.<a href="correlations.html#fnref3">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linearmodel.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="one-mean.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["stat_tests.pdf", "stat_tests.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
