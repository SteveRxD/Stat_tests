<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 7 Three or more means | Common statistical tests are linear models: a work through</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 7 Three or more means | Common statistical tests are linear models: a work through" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Three or more means | Common statistical tests are linear models: a work through" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Steve Doogue">


<meta name="date" content="2019-07-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="two-means-independent-samples.html">
<link rel="next" href="proportions-and-chi-squared.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical tests as linear models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>2</b> The data</a><ul>
<li class="chapter" data-level="2.1" data-path="data.html"><a href="data.html#samplevalues"><i class="fa fa-check"></i><b>2.1</b> Sample values</a></li>
<li class="chapter" data-level="2.2" data-path="data.html"><a href="data.html#ranktrans"><i class="fa fa-check"></i><b>2.2</b> ‘Signed rank’ values</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linearmodel.html"><a href="linearmodel.html"><i class="fa fa-check"></i><b>3</b> The linear model</a><ul>
<li class="chapter" data-level="3.1" data-path="linearmodel.html"><a href="linearmodel.html#overview-of-the-linear-model"><i class="fa fa-check"></i><b>3.1</b> Overview of the linear model</a></li>
<li class="chapter" data-level="3.2" data-path="linearmodel.html"><a href="linearmodel.html#estimating-linear-models-in-r"><i class="fa fa-check"></i><b>3.2</b> Estimating linear models in R</a></li>
<li class="chapter" data-level="3.3" data-path="linearmodel.html"><a href="linearmodel.html#assumptions"><i class="fa fa-check"></i><b>3.3</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="correlations.html"><a href="correlations.html"><i class="fa fa-check"></i><b>4</b> Correlations</a><ul>
<li class="chapter" data-level="4.1" data-path="correlations.html"><a href="correlations.html#pearson-correlation"><i class="fa fa-check"></i><b>4.1</b> Pearson correlation</a></li>
<li class="chapter" data-level="4.2" data-path="correlations.html"><a href="correlations.html#spearman-correlation"><i class="fa fa-check"></i><b>4.2</b> Spearman correlation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="one-mean.html"><a href="one-mean.html"><i class="fa fa-check"></i><b>5</b> One mean</a><ul>
<li class="chapter" data-level="5.1" data-path="one-mean.html"><a href="one-mean.html#one-sample"><i class="fa fa-check"></i><b>5.1</b> One sample</a><ul>
<li class="chapter" data-level="5.1.1" data-path="one-mean.html"><a href="one-mean.html#one-sample-t-test"><i class="fa fa-check"></i><b>5.1.1</b> One-sample t-test</a></li>
<li class="chapter" data-level="5.1.2" data-path="one-mean.html"><a href="one-mean.html#wilcoxen-signed-rank"><i class="fa fa-check"></i><b>5.1.2</b> Wilcoxen signed-rank</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="one-mean.html"><a href="one-mean.html#paired-samples"><i class="fa fa-check"></i><b>5.2</b> Paired samples</a><ul>
<li class="chapter" data-level="5.2.1" data-path="one-mean.html"><a href="one-mean.html#paired-sample-t-test"><i class="fa fa-check"></i><b>5.2.1</b> Paired-sample t-test</a></li>
<li class="chapter" data-level="5.2.2" data-path="one-mean.html"><a href="one-mean.html#wilcoxen-matched-pairs"><i class="fa fa-check"></i><b>5.2.2</b> Wilcoxen matched pairs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html"><i class="fa fa-check"></i><b>6</b> Two means (independent samples)</a><ul>
<li class="chapter" data-level="6.1" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#independent-t-test"><i class="fa fa-check"></i><b>6.1</b> Independent t-test</a></li>
<li class="chapter" data-level="6.2" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#welchs-t-test"><i class="fa fa-check"></i><b>6.2</b> Welch’s t-test</a></li>
<li class="chapter" data-level="6.3" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#mann-whitney-u-test"><i class="fa fa-check"></i><b>6.3</b> Mann-Whitney U test</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="three-or-more-means.html"><a href="three-or-more-means.html"><i class="fa fa-check"></i><b>7</b> Three or more means</a><ul>
<li class="chapter" data-level="7.1" data-path="three-or-more-means.html"><a href="three-or-more-means.html#one-way-anova"><i class="fa fa-check"></i><b>7.1</b> One-way ANOVA</a><ul>
<li class="chapter" data-level="7.1.1" data-path="three-or-more-means.html"><a href="three-or-more-means.html#kruskal-wallis"><i class="fa fa-check"></i><b>7.1.1</b> Kruskal-Wallis</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="three-or-more-means.html"><a href="three-or-more-means.html#two-way-anova"><i class="fa fa-check"></i><b>7.2</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="7.3" data-path="three-or-more-means.html"><a href="three-or-more-means.html#ancova"><i class="fa fa-check"></i><b>7.3</b> ANCOVA</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="proportions-and-chi-squared.html"><a href="proportions-and-chi-squared.html"><i class="fa fa-check"></i><b>8</b> Proportions and chi squared</a><ul>
<li class="chapter" data-level="8.1" data-path="proportions-and-chi-squared.html"><a href="proportions-and-chi-squared.html#goodness-of-fit"><i class="fa fa-check"></i><b>8.1</b> Goodness of fit</a></li>
<li class="chapter" data-level="8.2" data-path="proportions-and-chi-squared.html"><a href="proportions-and-chi-squared.html#contingency-tables"><i class="fa fa-check"></i><b>8.2</b> Contingency tables</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="appendixtypes.html"><a href="appendixtypes.html"><i class="fa fa-check"></i><b>9</b> Appendix - Types of variables</a><ul>
<li class="chapter" data-level="9.1" data-path="appendixtypes.html"><a href="appendixtypes.html#discrete-variables"><i class="fa fa-check"></i><b>9.1</b> Discrete variables</a></li>
<li class="chapter" data-level="9.2" data-path="appendixtypes.html"><a href="appendixtypes.html#continuous-variables"><i class="fa fa-check"></i><b>9.2</b> Continuous variables</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Common statistical tests are linear models: a work through</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="three-or-more-means" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Three or more means</h1>
<div id="one-way-anova" class="section level2">
<h2><span class="header-section-number">7.1</span> One-way ANOVA</h2>
<p>The one-way analysis of variance (ANOVA) is used to determine whether there are any statistically significant differences between the means of three or more independent groups.</p>
<p>Examples include:</p>
<ul>
<li>Is there a difference in academic outcomes for pupils from ten different schools?</li>
<li>Is there a difference daily coffee consumption between people in three different countries?</li>
</ul>
<p>Intuitively, ANOVA is based on comparing the variance (or variation) between the groups, to variation within each particular group. If the ‘between’ variation is much larger than the ‘within’ variation, we are more likely to conclude that the means of the different groups are not equal. If the ‘between’ and ‘within’ variations are more similar in size, then we are less likely to conclude that there is a significant difference between sample means.</p>
<p>Why can’t we just compare the means of every possible pair of groups, and see if any differences are statistically significant? The reason is that as the number of groups increases, the more likely we are to see differences that are due to chance alone. This means we are more likely to commit a Type I error, rejecting the null hypothesis (that there is no difference between the means) when the null hypothesis is in fact true.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> An ANOVA controls for this additional risk of Type I errors, maintaining the overall or experimentwise error rate, which is typically <span class="math inline">\(\alpha\)</span> = 0.05.</p>
<p>It is important to note that the one-way ANOVA is an omnibus test statistic and cannot tell you <em>which</em> specific groups were statistically significantly different from each other, only that at least two groups were different. To determine which specific groups differed from each other, you would need to use a post hoc test.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></p>
<p><strong>Dataset:</strong></p>
<p>To illustrate, we will create a new dataset (<code>mydata_anova1</code>). We assume three groups (A, B and C) of normally-distributed variables, with means of 0, 1 and 0.5 respectively. We also create dummy variables for groups B and C (group A is our reference group, and so does not require an indicator):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create dataset &#39;mydata_anova1&#39; which is three groups:</span>
<span class="kw">set.seed</span>(<span class="dv">40</span>)                      <span class="co"># Makes the randomised figures reproducible</span>
N &lt;-<span class="st"> </span><span class="dv">20</span>                           <span class="co"># Sample size of 20 for each group</span>
mydata_anova1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
                    <span class="dt">value =</span> <span class="kw">c</span>(<span class="kw">rnorm_fixed</span>(N,<span class="dt">mu =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>),     <span class="co"># Group A</span>
                              <span class="kw">rnorm_fixed</span>(N, <span class="dt">mu =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="dv">1</span>),    <span class="co"># Group B</span>
                              <span class="kw">rnorm_fixed</span>(N, <span class="dt">mu =</span> <span class="fl">0.5</span>, <span class="dt">sd =</span> <span class="dv">1</span>)), <span class="co"># Group C</span>
                    <span class="dt">group =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>), <span class="dt">each=</span>N)
                    ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># Explicitly add indicator/dummy variables</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">group_b =</span> <span class="kw">if_else</span>(group <span class="op">==</span><span class="st"> &#39;b&#39;</span>, <span class="dv">1</span> , <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st">             </span><span class="co"># Group B dummy</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">group_c =</span> <span class="kw">if_else</span>(group <span class="op">==</span><span class="st"> &#39;c&#39;</span>, <span class="dv">1</span> , <span class="dv">0</span>))                 <span class="co"># Group C dummy</span></code></pre></div>
<p>Here’s a sample of six rows from our new dataset, which includes the dummy variables:</p>
<table>
<caption><span id="tab:unnamed-chunk-38">Table 7.1: </span>Some randomly selected rows from our dataset</caption>
<thead>
<tr class="header">
<th align="right">value</th>
<th align="left">group</th>
<th align="right">group_b</th>
<th align="right">group_c</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.5685977</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">0.5873537</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">2.2828164</td>
<td align="left">b</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">0.5557109</td>
<td align="left">b</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1.2658245</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">0.1858697</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>Note that the data used in the remainder of this book varies from that used by Lindeløv in the original version, but the principles being discussed are exactly the same.</p>
<p><strong>ANOVA function:</strong></p>
<p>R has a package for ANOVA, in this case <code>car::Anova(aov())</code>. However, this is simply a ‘wrapper’ around the equivalent linear model, described below, and yields identical results.</p>
<p><strong>Equivalent linear model:</strong></p>
<p>The linear model assumes that the dependent variable can be predicted with a single mean for each group:</p>
<p><span class="math inline">\(y = \beta_0 + \beta_1 \cdot x_1 + \beta_2 \cdot x_2 + ... \qquad H_0: y = \beta_0\)</span></p>
<p>This assumption is illustrated below, in which there are assumed to be three groups (A, B and C). This extends the case with two groups, as was illustrated in the previous chapter, to cases with three or more groups. In this case, members of group B are identified by the dummy variable <span class="math inline">\(x_1\)</span>, with the coefficient (or slope) of <span class="math inline">\(\beta_1\)</span>, and members of group C are identified by the variable <span class="math inline">\(x_2\)</span>, with the slope of <span class="math inline">\(\beta_2\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:dummy3"></span>
<img src="images/image_dummy2.png" alt="Linear model equivalent to ANOVA with three groups" width="75%" />
<p class="caption">
Figure 7.1: Linear model equivalent to ANOVA with three groups
</p>
</div>
<p>The null hypothesis of the linear model is that <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are both zero; or equivalently, that all groups have the same mean of <span class="math inline">\(\beta_0\)</span>. To test this hypothesis, an <a href="https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/f-statistic-value-test/">F-test</a> is used. The F statistic in a regression is the result of a test where the null hypothesis is that all of the regression coefficients are equal to zero. The F-test compares your full model to one with no predictor variables (the intercept only model), and decides whether your added variables improved the model. If you get a significant result, then whatever coefficients you included in your full model improved the model’s fit (beyond what could be expected by chance alone).</p>
<p>In R, an F-test is carried out every time you run a linear regression, i.e. you do not have to specify it as an additional test.</p>
<p><strong>Comparison:</strong></p>
<p>The following code compares the ANOVA test in R with the identical linear model using dummy variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Anova</span>
car<span class="op">::</span><span class="kw">Anova</span>(<span class="kw">aov</span>(value <span class="op">~</span><span class="st"> </span>group, <span class="dt">data =</span> mydata_anova1))

<span class="co"># Linear model</span>
lm &lt;-<span class="st"> </span><span class="kw">lm</span>(value <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_b <span class="op">+</span><span class="st"> </span>group_c, <span class="dt">data =</span> mydata_anova1)
  lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">digits =</span> <span class="dv">8</span>) <span class="co"># show summary output</span></code></pre></div>
<p>Here are the results, which are identical:</p>
<table>
<caption><span id="tab:unnamed-chunk-40">Table 7.2: </span>One-way ANOVA and equivalent linear model</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="right">df</th>
<th align="right">df.residual</th>
<th align="right">F.statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Anova</td>
<td align="right">2</td>
<td align="right">57</td>
<td align="right">5</td>
<td align="right">0.00998</td>
</tr>
<tr class="even">
<td align="left">lm</td>
<td align="right">2</td>
<td align="right">57</td>
<td align="right">5</td>
<td align="right">0.00998</td>
</tr>
</tbody>
</table>
<p>Here we would reject the null hypothesis that there was no differences between the means of any of our groups at the 0.05 level of significance (because p = 0.00998).</p>
<p>It should be emphasised that the results of the ANOVA and the linear model are identical <em>by construction</em>, as they are both an F-test that compares the full model (with group dummies) to a model with an intercept only.</p>
<div id="kruskal-wallis" class="section level3">
<h3><span class="header-section-number">7.1.1</span> Kruskal-Wallis</h3>
<p>The non-parametric version of the ANOVA is the Kruskal-Wallis test. We would need to use this test if our dependent variable was ordinal rather than continuous. We would also use the non-parametric version if other assumptions of the one-way ANOVA did not hold, including (1) that the dependent variable was approximately normally distributed for each category of the independent variable, and (2) homogeneity of variances.</p>
<p><strong>Equivalent linear model:</strong></p>
<p>The Kruskal-Wallis is essentially a one-way ANOVA test on <strong>ranks</strong>. It can be expressed as the following linear model:</p>
<p><span class="math inline">\(rank(y) = \beta_0 + \beta_1 \cdot x_1 + \beta_2 \cdot x_2 + ... \qquad H_0: y = \beta_0\)</span></p>
<p><strong>Comparison:</strong></p>
<p>Here is a comparison of the Kruskal-Wallis test and the equivalent linear model (the equivalent ANOVA test is also included for completeness, which we’ve seen is just a ‘wrap’ around the linear model).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Kruskal-Wallis</span>
<span class="kw">kruskal.test</span>(value <span class="op">~</span><span class="st"> </span>group, <span class="dt">data =</span> mydata_anova1)

<span class="co"># Linear model on ranks</span>
lm &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">rank</span>(value) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_b <span class="op">+</span><span class="st"> </span>group_c, <span class="dt">data =</span> mydata_anova1)
  lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">digits =</span> <span class="dv">8</span>) <span class="co"># show summary output</span>

<span class="co"># Anova on ranks (which is a wrapper around the linear model above)</span>
car<span class="op">::</span><span class="kw">Anova</span>(<span class="kw">aov</span>(<span class="kw">rank</span>(value) <span class="op">~</span><span class="st"> </span>group, <span class="dt">data =</span> mydata_anova1))</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-42">Table 7.3: </span>Kruskal-Wallis test and equivalent linear model</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="right">df</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Kruskal</td>
<td align="right">2</td>
<td align="right">0.0203</td>
</tr>
<tr class="even">
<td align="left">lm</td>
<td align="right">2</td>
<td align="right">0.0177</td>
</tr>
</tbody>
</table>
<p>The p-value of the two tests are similar, though not identical. In this example, we would reject the null hypothesis that all groups had equal means (at the 0.05 level of significance).</p>
</div>
</div>
<div id="two-way-anova" class="section level2">
<h2><span class="header-section-number">7.2</span> Two-way ANOVA</h2>
<p>The two-way ANOVA compares the means of groups that have been split on two independent variables, or ‘factors’.</p>
<p>For example: is there an interaction between gender and educational level on test anxiety among university students? Here gender (males / females) and education level (high school / undergraduate / postgraduate) are your independent variables or factors.</p>
<p>A two-way ANOVA tests three hypotheses:</p>
<ul>
<li>That the population means of the first factor (e.g. each gender) are equal;</li>
<li>That the population means of the second factor (e.g. each education level) are equal; and</li>
<li>That there is no interaction between the two factors - i.e. that the relationship between anxiety and gender does not depend on education level, or that the relationship between anxiety and education does not depend on gender.</li>
</ul>
<p>The first two hypotheses relate to the relationship between each factor and the dependent variable, referred to as ‘main effects’. Each of these is like a one-way ANOVA, but in the context of a larger model. The third hypothesis relates to the ‘interaction effect’. Here we will focus on the interaction effect.</p>
<p><strong>Updated dataset:</strong></p>
<p>To show the modelling in R, we’ll add another factor to our example dataset, <code>mood</code>, which reports whether a person is happy or sad. We also use this to create a dummy variable, <code>mood_happy</code>, which takes the value of 1 if the person is happy or 0 if they are sad.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mydata_anova2 &lt;-<span class="st"> </span>mydata_anova1 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mood =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&#39;happy&#39;</span>,<span class="st">&#39;sad&#39;</span>),<span class="dv">30</span>)) <span class="op">%&gt;%</span><span class="st">        </span><span class="co"># 60 observations in total</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mood_happy =</span> <span class="kw">if_else</span>(mood <span class="op">==</span><span class="st"> &#39;happy&#39;</span>,<span class="dv">1</span>,<span class="dv">0</span>))  <span class="co"># The dummy variable</span></code></pre></div>
<p>Here’s a selection of six rows from the updated dataset:</p>
<table>
<caption><span id="tab:unnamed-chunk-44">Table 7.4: </span>Some randomly selected rows from our dataset</caption>
<thead>
<tr class="header">
<th align="right">value</th>
<th align="left">group</th>
<th align="right">group_b</th>
<th align="right">group_c</th>
<th align="left">mood</th>
<th align="right">mood_happy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.5685977</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">happy</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">0.5873537</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">sad</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">2.2828164</td>
<td align="left">b</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="left">happy</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">0.5557109</td>
<td align="left">b</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="left">sad</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1.2658245</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">happy</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">0.1858697</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">sad</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Equivalent linear model:</strong></p>
<p>The two-way ANOVA can test for the interaction between two factors (let’s ignore the main effects for now). It is equivalent to the following linear model, which is now expressed using matrix notation:</p>
<p><span class="math inline">\(y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_2 X_3 \qquad H_0: \beta_3 = 0\)</span></p>
<p>Here <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> represent the two factors in our model (in this example, the ‘group’ and ‘mood’ of each observation, respectively). Each <span class="math inline">\(\beta_i\)</span> is a vector of values that relates to the levels within each factor. In our example, <span class="math inline">\(\beta_1\)</span> will have two values that correspond to the group dummy variables (<code>group_b</code> and <code>group_c</code>) and <span class="math inline">\(\beta_2\)</span> will be single value corresponding to the dummy variable for mood (<code>mood_happy</code>). The intercept <span class="math inline">\(\beta_0\)</span>, to which all other <span class="math inline">\(\beta\)</span>s are relative, is now the mean for the first level of all factors (people in group A who are sad).</p>
<p><span class="math inline">\(\beta_3\)</span> is a vector that relates to the interactions of the factors. Here, it will be a vector comprising two values, corresponding to the combinations of the group and mood dummy variables (<code>group_b</code> and <code>mood_happy</code>, and <code>group_c</code> and <code>mood_happy</code>). The null hypothesis (of <span class="math inline">\(\beta_3 = 0\)</span>) is that all values in this vector are zero, and that there is no interaction between group and mood when explaining the dependent variable, <code>value</code>.</p>
<p>To test this null hypothesis, we are going to carry out an F-test of two nested models:</p>
<ul>
<li>a full model, which includes both factors and the interaction terms; and</li>
<li>a restricted or null model, which includes both factors but no interaction term.</li>
</ul>
<p>This is similar to the F-test used in the one-way ANOVA above, but in this case our null model includes the two factors and not just an intercept term.</p>
<p><strong>Comparison:</strong></p>
<p>The code for running the ANOVA, using the package in R, is as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Two-way ANOVA, built-in function</span>
car<span class="op">::</span><span class="kw">Anova</span>(<span class="kw">aov</span>(value <span class="op">~</span><span class="st"> </span>mood <span class="op">+</span><span class="st"> </span>group <span class="op">+</span><span class="st"> </span>mood<span class="op">:</span>group, <span class="dt">data =</span> mydata_anova2)) </code></pre></div>
<p>The equivalent linear model, which includes an interaction between the two group dummy variables and the mood dummy variable, is specified as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(value <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_b <span class="op">+</span><span class="st"> </span>group_c <span class="op">+</span><span class="st"> </span>mood_happy <span class="op">+</span><span class="st"> </span>group_b<span class="op">:</span>mood_happy <span class="op">+</span><span class="st"> </span>group_c<span class="op">:</span>mood_happy, 
        <span class="dt">data =</span> mydata_anova2)</code></pre></div>
<p>The results of the above model will give us the p-values of <em>all</em> the interaction terms (in this case, two) and tell us if any of these are statistically significant. But recall that our null hypothesis is that <em>none</em> of the interaction terms are significant, and we can’t rely on individual tests for this because of the increased risk of errors (as explained in the previous section on one-way ANOVAs). This is why we use the two-way ANOVA, which is an F-test that compares the full and null models:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># null model, without interactions</span>
null &lt;-<span class="st"> </span><span class="kw">lm</span>(value <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_b <span class="op">+</span><span class="st"> </span>group_c <span class="op">+</span><span class="st"> </span>mood_happy, <span class="dt">data =</span> mydata_anova2)

<span class="co"># full model, with interactions</span>
full &lt;-<span class="st"> </span><span class="kw">lm</span>(value <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_b <span class="op">+</span><span class="st"> </span>group_c <span class="op">+</span><span class="st"> </span>mood_happy <span class="op">+</span><span class="st"> </span>group_b<span class="op">:</span>mood_happy <span class="op">+</span>
<span class="st">             </span>group_c<span class="op">:</span>mood_happy, <span class="dt">data =</span> mydata_anova2)

<span class="co"># ANOVA using the two models above. </span>
<span class="kw">anova</span>(null,full, <span class="dt">test =</span> <span class="st">&quot;F&quot;</span>)    <span class="co"># anova() uses an F test by default,</span>
                                <span class="co"># but here it&#39;s made explicit</span></code></pre></div>
<p>The results of the two approaches are presented in the table below. This shows that the two approaches are identical F-tests with the same resulting p-value.</p>
<table>
<caption><span id="tab:unnamed-chunk-48">Table 7.5: </span>Two-way ANOVA and equivalent linear model</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="right">df</th>
<th align="right">df.res</th>
<th align="right">F.value</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ANOVA</td>
<td align="right">2</td>
<td align="right">54</td>
<td align="right">0.2977</td>
<td align="right">0.7437</td>
</tr>
<tr class="even">
<td align="left">lm</td>
<td align="right">2</td>
<td align="right">54</td>
<td align="right">0.2977</td>
<td align="right">0.7437</td>
</tr>
</tbody>
</table>
<p>On this basis of the test above, we would fail to reject the null hypothesis that there was no interaction between the two factors in our model (group and mood), at the 0.05 level of significance.</p>
</div>
<div id="ancova" class="section level2">
<h2><span class="header-section-number">7.3</span> ANCOVA</h2>
<p>This adds a <em>continuous</em> independent variable, or covariate, to the model (e.g. age), in addition to one or more categorical independent variables (e.g. gender or education level).</p>
<p>An analysis of covariance (ANCOVA) evaluates whether the mean of the dependent variable is equal across levels of a categorical independent variable, while statistically controlling for the effects of other continuous variables (e.g. age) that are not of primary interest, known as covariates.</p>
<p><strong>Updated dataset:</strong></p>
<p>Here will will add a covariate to our one-way ANOVA above. In addition to the <code>group</code> dummy variables, we update our data set to include each subject’s <code>age</code>, which we assume is correlated with the dependent variable, <code>value</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create a new column with the continuous variable &#39;age&#39;</span>
mydata_anova3 &lt;-<span class="st"> </span>mydata_anova1 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">age =</span> value <span class="op">+</span><span class="st"> </span><span class="kw">rnorm_fixed</span>(<span class="kw">nrow</span>(.),<span class="dt">sd =</span> <span class="dv">3</span>))</code></pre></div>
<p>Here’s a selection of six rows from the updated dataset:</p>
<table>
<caption><span id="tab:unnamed-chunk-50">Table 7.6: </span>Some randomly selected rows from our dataset</caption>
<thead>
<tr class="header">
<th align="right">value</th>
<th align="left">group</th>
<th align="right">group_b</th>
<th align="right">group_c</th>
<th align="right">age</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.5685977</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">-3.6341563</td>
</tr>
<tr class="even">
<td align="right">0.5873537</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3.1155833</td>
</tr>
<tr class="odd">
<td align="right">2.2828164</td>
<td align="left">b</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">2.4620050</td>
</tr>
<tr class="even">
<td align="right">0.5557109</td>
<td align="left">b</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">-3.5019533</td>
</tr>
<tr class="odd">
<td align="right">1.2658245</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.8547244</td>
</tr>
<tr class="even">
<td align="right">0.1858697</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">-1.0090546</td>
</tr>
</tbody>
</table>
<p><strong>ANOVA function:</strong></p>
<p>An ANCOVA can be carried out using the <code>Anova()</code> function and including the covariate (in this case <code>age</code>) as an independent variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">car<span class="op">::</span><span class="kw">Anova</span>(<span class="kw">aov</span>(value <span class="op">~</span><span class="st"> </span>group <span class="op">+</span><span class="st"> </span>age, mydata_anova3))</code></pre></div>
<p><strong>Equivalent linear model:</strong></p>
<p>The same results can be achieved by using F-tests to compare two sets of linear models: (i) the full model and the nested model which excludes <code>age</code>, and (ii) the full model and the nested model that excludes the <code>group</code> dummy variables. Again, the F-tests are carried out using the <code>anova()</code> function, which uses an F-test by default.</p>
<p>The full model can be formulated as follows:</p>
<p><span class="math inline">\(y = \beta_0 + \beta_1 \cdot x_1 + \beta_2 \cdot x_2 + ... + \beta_3 \cdot age\)</span></p>
<p>where the value of <span class="math inline">\(y\)</span> varies by group, as represented here by the dummy variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, and also by <span class="math inline">\(age\)</span>.</p>
<p>This can be illustrated below. The ANCOVA tests whether there is difference in the mean <code>y</code> for the three groups, after controlling for age (the vertical shift shown by <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>). It also tests whether the slope <span class="math inline">\((\beta_3)\)</span> is statistically significant.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-52"></span>
<img src="images/image_ancova.png" alt="Linear model equivalent to ANCOVA with three groups" width="75%" />
<p class="caption">
Figure 7.2: Linear model equivalent to ANCOVA with three groups
</p>
</div>
<p>Here we run the linear model in R. The resulting p-values relate to the null hypotheses that <code>age</code> and <code>group</code> (respectively) have no effect on the dependent variable, in this case <code>value</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># full model, with group and age variables</span>
full &lt;-<span class="st"> </span><span class="kw">lm</span>(value <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_b <span class="op">+</span><span class="st"> </span>group_c <span class="op">+</span><span class="st"> </span>age, mydata_anova3)
<span class="co"># model without age </span>
null_age &lt;-<span class="st"> </span><span class="kw">lm</span>(value <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_b <span class="op">+</span><span class="st"> </span>group_c, mydata_anova3)
<span class="co"># model without groups</span>
null_group&lt;-<span class="st"> </span><span class="kw">lm</span>(value <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>age, mydata_anova3)
<span class="co"># result for age</span>
<span class="kw">anova</span>(null_age, full)
<span class="co"># results of group</span>
<span class="kw">anova</span>(null_group, full)</code></pre></div>
<p><strong>Comparison:</strong></p>
<p>The results of the two approaches are presented in the table below:</p>
<table>
<caption><span id="tab:unnamed-chunk-54">Table 7.7: </span>ANCOVA and linear model</caption>
<thead>
<tr class="header">
<th align="left">Term</th>
<th align="left">Model</th>
<th align="right">df</th>
<th align="left">res.df</th>
<th align="right">F.value</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">age</td>
<td align="left">Anova</td>
<td align="right">1</td>
<td align="left"></td>
<td align="right">5.2002</td>
<td align="right">0.02641</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="left">lm</td>
<td align="right">1</td>
<td align="left">56</td>
<td align="right">5.2002</td>
<td align="right">0.02641</td>
</tr>
<tr class="odd">
<td align="left">group</td>
<td align="left">Anova</td>
<td align="right">2</td>
<td align="left"></td>
<td align="right">4.6929</td>
<td align="right">0.01305</td>
</tr>
<tr class="even">
<td align="left">group</td>
<td align="left">lm</td>
<td align="right">2</td>
<td align="left">56</td>
<td align="right">4.6929</td>
<td align="right">0.01305</td>
</tr>
</tbody>
</table>
<p>Based on these results, we would reject the null hypothesis that there was no relationship between <code>value</code> and <code>group</code>, even after controlling for differences in <code>age</code>. We would also reject the null hypothesis that <code>value</code> was not related to <code>age</code>.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>For example, if there were only two groups, we would be carrying out one comparison: the mean of Group A vs the mean of Group B. At a 0.05 level of significance, there would be a 5% chance of a Type I error. If we had three groups, there would be three comparisons (Group A vs Group B, Group A vs Group C, and Group B vs Group C), and we would have a 14.3% (1-0.95^3) chance of a Type I error.<a href="three-or-more-means.html#fnref5">↩</a></p></li>
<li id="fn6"><p>Post hoc tests attempt to control the experimentwise error rate (usually <span class="math inline">\(\alpha\)</span> = 0.05) in the same manner that the one-way ANOVA is used instead of multiple t-tests. <a href="https://statistics.laerd.com/statistical-guides/one-way-anova-statistical-guide-4.php">Laerd</a> suggests using the Tukey test (where there is homogeneity of variances in your samples) or the Games Howell test (where there is not).<a href="three-or-more-means.html#fnref6">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="two-means-independent-samples.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="proportions-and-chi-squared.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["stat_tests.pdf", "stat_tests.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
