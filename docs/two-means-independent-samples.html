<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 6 Two means (independent samples) | Common statistical tests are linear models: a work through</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 6 Two means (independent samples) | Common statistical tests are linear models: a work through" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Two means (independent samples) | Common statistical tests are linear models: a work through" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Steve Doogue">


<meta name="date" content="2019-07-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="one-mean.html">
<link rel="next" href="three-or-more-means.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical tests as linear models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>2</b> The data</a><ul>
<li class="chapter" data-level="2.1" data-path="data.html"><a href="data.html#samplevalues"><i class="fa fa-check"></i><b>2.1</b> Sample values</a></li>
<li class="chapter" data-level="2.2" data-path="data.html"><a href="data.html#ranktrans"><i class="fa fa-check"></i><b>2.2</b> ‘Signed rank’ values</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linearmodel.html"><a href="linearmodel.html"><i class="fa fa-check"></i><b>3</b> The linear model</a><ul>
<li class="chapter" data-level="3.1" data-path="linearmodel.html"><a href="linearmodel.html#overview-of-the-linear-model"><i class="fa fa-check"></i><b>3.1</b> Overview of the linear model</a></li>
<li class="chapter" data-level="3.2" data-path="linearmodel.html"><a href="linearmodel.html#estimating-linear-models-in-r"><i class="fa fa-check"></i><b>3.2</b> Estimating linear models in R</a></li>
<li class="chapter" data-level="3.3" data-path="linearmodel.html"><a href="linearmodel.html#assumptions"><i class="fa fa-check"></i><b>3.3</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="correlations.html"><a href="correlations.html"><i class="fa fa-check"></i><b>4</b> Correlations</a><ul>
<li class="chapter" data-level="4.1" data-path="correlations.html"><a href="correlations.html#pearson-correlation"><i class="fa fa-check"></i><b>4.1</b> Pearson correlation</a></li>
<li class="chapter" data-level="4.2" data-path="correlations.html"><a href="correlations.html#spearman-correlation"><i class="fa fa-check"></i><b>4.2</b> Spearman correlation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="one-mean.html"><a href="one-mean.html"><i class="fa fa-check"></i><b>5</b> One mean</a><ul>
<li class="chapter" data-level="5.1" data-path="one-mean.html"><a href="one-mean.html#one-sample"><i class="fa fa-check"></i><b>5.1</b> One sample</a><ul>
<li class="chapter" data-level="5.1.1" data-path="one-mean.html"><a href="one-mean.html#one-sample-t-test"><i class="fa fa-check"></i><b>5.1.1</b> One-sample t-test</a></li>
<li class="chapter" data-level="5.1.2" data-path="one-mean.html"><a href="one-mean.html#wilcoxen-signed-rank"><i class="fa fa-check"></i><b>5.1.2</b> Wilcoxen signed-rank</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="one-mean.html"><a href="one-mean.html#paired-samples"><i class="fa fa-check"></i><b>5.2</b> Paired samples</a><ul>
<li class="chapter" data-level="5.2.1" data-path="one-mean.html"><a href="one-mean.html#paired-sample-t-test"><i class="fa fa-check"></i><b>5.2.1</b> Paired-sample t-test</a></li>
<li class="chapter" data-level="5.2.2" data-path="one-mean.html"><a href="one-mean.html#wilcoxen-matched-pairs"><i class="fa fa-check"></i><b>5.2.2</b> Wilcoxen matched pairs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html"><i class="fa fa-check"></i><b>6</b> Two means (independent samples)</a><ul>
<li class="chapter" data-level="6.1" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#independent-t-test"><i class="fa fa-check"></i><b>6.1</b> Independent t-test</a></li>
<li class="chapter" data-level="6.2" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#welchs-t-test"><i class="fa fa-check"></i><b>6.2</b> Welch’s t-test</a></li>
<li class="chapter" data-level="6.3" data-path="two-means-independent-samples.html"><a href="two-means-independent-samples.html#mann-whitney-u-test"><i class="fa fa-check"></i><b>6.3</b> Mann-Whitney U test</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="three-or-more-means.html"><a href="three-or-more-means.html"><i class="fa fa-check"></i><b>7</b> Three or more means</a><ul>
<li class="chapter" data-level="7.1" data-path="three-or-more-means.html"><a href="three-or-more-means.html#one-way-anova"><i class="fa fa-check"></i><b>7.1</b> One-way ANOVA</a><ul>
<li class="chapter" data-level="7.1.1" data-path="three-or-more-means.html"><a href="three-or-more-means.html#kruskal-wallis"><i class="fa fa-check"></i><b>7.1.1</b> Kruskal-Wallis</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="three-or-more-means.html"><a href="three-or-more-means.html#two-way-anova"><i class="fa fa-check"></i><b>7.2</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="7.3" data-path="three-or-more-means.html"><a href="three-or-more-means.html#ancova"><i class="fa fa-check"></i><b>7.3</b> ANCOVA</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="proportions-and-chi-squared.html"><a href="proportions-and-chi-squared.html"><i class="fa fa-check"></i><b>8</b> Proportions and chi squared</a><ul>
<li class="chapter" data-level="8.1" data-path="proportions-and-chi-squared.html"><a href="proportions-and-chi-squared.html#goodness-of-fit"><i class="fa fa-check"></i><b>8.1</b> Goodness of fit</a></li>
<li class="chapter" data-level="8.2" data-path="proportions-and-chi-squared.html"><a href="proportions-and-chi-squared.html#contingency-tables"><i class="fa fa-check"></i><b>8.2</b> Contingency tables</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="appendixtypes.html"><a href="appendixtypes.html"><i class="fa fa-check"></i><b>9</b> Appendix - Types of variables</a><ul>
<li class="chapter" data-level="9.1" data-path="appendixtypes.html"><a href="appendixtypes.html#discrete-variables"><i class="fa fa-check"></i><b>9.1</b> Discrete variables</a></li>
<li class="chapter" data-level="9.2" data-path="appendixtypes.html"><a href="appendixtypes.html#continuous-variables"><i class="fa fa-check"></i><b>9.2</b> Continuous variables</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Common statistical tests are linear models: a work through</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="two-means-independent-samples" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Two means (independent samples)</h1>
<p>These tests compare the means of two independent or unrelated groups, in order to determine whether there is statistical evidence that the population means are significantly different. Examples include:</p>
<ul>
<li>Do first year graduate salaries differ based on gender? and<br />
</li>
<li>Is there is a difference in test anxiety based on educational level (undergraduate vs postgraduate)?</li>
</ul>
<p>A key question is whether or not the <strong>variances</strong> of the two samples being tested are equal.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> In general terms:</p>
<ul>
<li>If the samples have <em>equal</em> variance then an <strong>independent-sample t-test</strong> (Student’s t-test) could be used.</li>
<li>If the samples have <em>unequal</em> variance then the <strong>Welch’s t-test</strong> can be used, as this does not assume identical variances.</li>
<li>If the samples are <em>not normally distibuted</em>, or if the other requirements of the above tests are not met, then the non-parametric <strong>Mann-Whitney U</strong> test could be used.</li>
</ul>
<p>This is somewhat simplistic, and the choice of tests is not always clear (see the discussion <a href="https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl">here</a> on StackExchange for example). The following sections goes through each of these tests in turn, and describes how they can be approximated by an equivalent linear model.</p>
<div id="independent-t-test" class="section level2">
<h2><span class="header-section-number">6.1</span> Independent t-test</h2>
<p>The independent t-test can be used to compare the means of two unrelated groups. Assumptions include:</p>
<ul>
<li>Independence of observations (independent samples / groups);</li>
<li>Normal distribution (approximately) of the dependent variable for each group, though this might not be an issue for large samples;</li>
<li>No outliers; and</li>
<li>Homogeneity of variances; i.e. variances are approximately equal across the two groups.</li>
</ul>
<p><strong>Student’s t-test:</strong></p>
<p>In R, we can assesses the difference between two groups using the <a href="https://www.rdocumentation.org/packages/stats/versions/3.5.3/topics/t.test">t.test</a>. This has the default assumptions that the two samples are <em>not</em> paired, and that their variances are <em>not</em> equal.</p>
<p><strong>Equivalent linear model:</strong></p>
<p>The equivalent linear model uses a dummy variable to represent the two groups (see the explanation of dummy variables explained by Lindeløv in section 5.1.3 of the <a href="https://lindeloev.github.io/tests-as-linear/#51_independent_t-test_and_mann-whitney_u">original book</a>).</p>
<p>The linear model takes the form:</p>
<p><span class="math inline">\(y = \beta_0 + \beta_1 \cdot x_i \qquad H_0: \beta_0 = 0\)</span></p>
<p>where <span class="math inline">\(x_i\)</span> is a dummy variable taking the value of 0 or 1, indicating whether observation <span class="math inline">\(i\)</span> is from the reference group (0) or the other group (1). For example, <span class="math inline">\(y\)</span> could be a measure of income and <span class="math inline">\(x_i\)</span> could be a dummy variable taking the value of 0 for women and 1 for men.</p>
<p>The use of dummy variables is illustrated below. The intercept (<span class="math inline">\(\beta_0\)</span>) is the sample average for observations in our reference group (in this example, women) when <span class="math inline">\(x = 0\)</span>. The slope (<span class="math inline">\(\beta_1\)</span>) is the difference in the averages of the two groups. In this example, when <span class="math inline">\(x = 1\)</span> (indicating men), the average salary is equal to <span class="math inline">\(\beta_0 + \beta_1\)</span>. Therefore, <span class="math inline">\(\beta_1\)</span> is the difference between the two groups, and we want to assess whether this difference is significantly different from zero.</p>
<div class="figure" style="text-align: center"><span id="fig:dummy2"></span>
<img src="images/image_dummy1.png" alt="Linear model equivalent to independent-sample t-test" width="65%" />
<p class="caption">
Figure 6.1: Linear model equivalent to independent-sample t-test
</p>
</div>
<p><br></p>
<p><strong>Comparison:</strong></p>
<p>Let’s say we want to compare the means of two groups in our example dataset, <code>y</code> and <code>y2</code>.</p>
<p>We start by creating a dummy variable to represent the two groups. The new variable is called <code>group_y2</code> and takes a value of 0 for observations in group <code>y</code> and a value of 1 for observations in group <code>y2</code>. This is done using the following code:</p>
<p>Here’s a sample of six rows from our new data set, which now includes the dummy variable:</p>
<table>
<caption><span id="tab:unnamed-chunk-29">Table 6.1: </span>Some randomly selected rows from our data set</caption>
<thead>
<tr class="header">
<th align="left">group</th>
<th align="right">value</th>
<th align="right">group_y2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">y</td>
<td align="right">1.1535602</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">y</td>
<td align="right">1.1881680</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">y</td>
<td align="right">-1.3557817</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">y2</td>
<td align="right">0.1030347</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">y2</td>
<td align="right">-0.2808907</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">y2</td>
<td align="right">0.6238886</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>Now we’ve organized our data, we can compare the results of the built-in independent t-test with the linear model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># independent t-test (built-in test)</span>
<span class="kw">t.test</span>(y2, y, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)
  <span class="co"># default is mu = 0, i.e. the null hypothesis that the difference in means is zero</span>

<span class="co"># Linear model</span>
lm &lt;-<span class="st"> </span><span class="kw">lm</span>(value <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_y2, <span class="dt">data =</span> mydata_dummy)
  lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">digits =</span> <span class="dv">8</span>) <span class="co"># show summary output</span>
  <span class="kw">confint</span>(lm) <span class="co"># show confidence intervals</span></code></pre></div>
<p>The outputs from the independent t-test and the equivalent linear model are shown below. The t statistic, p-value and confidence intervals are identical. While the t-test reports the averages of the two samples, the linear model reports the average of the reference group (0.3 for <code>y</code>) and the <em>difference</em> between the average of this reference group and the other group indicated by the dummy variable (a difference of +0.2). <br></p>
<table>
<caption><span id="tab:unnamed-chunk-31">Table 6.2: </span>Independent-sample t-test (equal variance) and linear model</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="right">mean.y</th>
<th align="left">mean.y2</th>
<th align="left">difference</th>
<th align="right">t</th>
<th align="right">p.value</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">t-test</td>
<td align="right">0.3</td>
<td align="left">0.5</td>
<td align="left"></td>
<td align="right">0.5657</td>
<td align="right">0.5729</td>
<td align="right">-0.5016</td>
<td align="right">0.9016</td>
</tr>
<tr class="even">
<td align="left">lm (with dummy)</td>
<td align="right">0.3</td>
<td align="left"></td>
<td align="left">0.2</td>
<td align="right">0.5657</td>
<td align="right">0.5729</td>
<td align="right">-0.5016</td>
<td align="right">0.9016</td>
</tr>
</tbody>
</table>
</div>
<div id="welchs-t-test" class="section level2">
<h2><span class="header-section-number">6.2</span> Welch’s t-test</h2>
<p>If the two samples have unequal variance then Welch’s t-test could be used.</p>
<p>In fact, <a href="http://daniellakens.blogspot.com/2015/01/always-use-welchs-t-test-instead-of.html">there is an argument</a> that we should use Welch’s t-test by default, rather than the independent Student’s t-test, because Welch’s t-test performs better than the t-test whenever sample sizes and variances are unequal between groups, and gives the same result when sample sizes and variances are equal.</p>
<p><strong>Welch’s t-test:</strong></p>
<p>The Welch t-test is identical to the independent-sample Student’s t-test described above, except that it does not assume equal variance of the two samples. In R, we can use the built-in <a href="https://www.rdocumentation.org/packages/stats/versions/3.5.3/topics/t.test">t.test</a>. When entering the code, we just need to specify that the sample variances are <strong>not equal</strong> (though this is the default assumption anyway).</p>
<p><strong>Equivalent linear model:</strong></p>
<p>The equivalent linear model is based on generalized least squares (GLS). The GLS approach makes the assumption that there is a relationship between the variance of observations and one of the independent variables used in our regression (in this example, the gender dummy variable). In a GLS regression, less weight is given to the observations with a higher variance.</p>
<p>We don’t know the true relationship between variance and our independent variable(s) in the underlying population, so this relationship is estimated from our sample. The estimate is based on the relationship between residuals (i.e. observed values minus predicted values, based on an OLS regression) and an independent variable. Once we have estimated this relationship, we then re-weight each observation in our sample by dividing each observation by the predicted variance. The final GLS regression is then run on these re-weighted observations. A more detailed explanation of the GLS approach (without using matrix algebra!) <a href="http://www.homepages.ucl.ac.uk/~uctpsc0/Teaching/GR03/Heter&amp;Autocorr.pdf">can be found here</a>.</p>
<p>In this example, when applying the GLS model in R, we specify that there is a different variance for group <code>y</code> and group <code>y2</code>.</p>
<p><strong>Comparison:</strong></p>
<p>The Welch’s t-test and the equivalent linear model are carried out as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="dt">digits=</span><span class="dv">10</span>)
<span class="co"># t-test (built-in test)</span>
<span class="kw">t.test</span>(y2, y, <span class="dt">mu =</span> <span class="dv">0</span>, <span class="dt">var.equal =</span> <span class="ot">FALSE</span>, <span class="dt">alternative =</span> <span class="st">&#39;two.sided&#39;</span>)
  <span class="co"># Note the assumption that variances are false</span>

<span class="co"># Linear model (GLS)</span>
lm &lt;-<span class="st"> </span>nlme<span class="op">::</span><span class="kw">gls</span>(value <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_y2, <span class="dt">weights =</span> nlme<span class="op">::</span><span class="kw">varIdent</span>(<span class="dt">form=</span><span class="op">~</span><span class="dv">1</span><span class="op">|</span>group), <span class="dt">method=</span><span class="st">&quot;ML&quot;</span>, <span class="dt">data=</span>mydata_dummy)
  lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">digits =</span> <span class="dv">8</span>) <span class="co"># show summary output</span>
  <span class="kw">confint</span>(lm) <span class="co"># show confidence intervals</span></code></pre></div>
<p>Here are the results, which are almost identical:</p>
<table>
<caption><span id="tab:unnamed-chunk-33">Table 6.3: </span>Independent-sample t-test (unequal variance) and GLS model</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="right">mean.y</th>
<th align="left">mean.y2</th>
<th align="left">difference</th>
<th align="right">t</th>
<th align="right">p.value</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">t-test</td>
<td align="right">0.3</td>
<td align="left">0.5</td>
<td align="left"></td>
<td align="right">0.5657</td>
<td align="right">0.5730</td>
<td align="right">-0.5023</td>
<td align="right">0.9023</td>
</tr>
<tr class="even">
<td align="left">lm (GLS)</td>
<td align="right">0.3</td>
<td align="left"></td>
<td align="left">0.2</td>
<td align="right">0.5657</td>
<td align="right">0.5729</td>
<td align="right">-0.4930</td>
<td align="right">0.8930</td>
</tr>
</tbody>
</table>
<p>Note that we get the same estimates for the means of <span class="math inline">\(y\)</span> and <span class="math inline">\(y_2\)</span> (of 0.3 and 0.5, respectively) from the t-test both with and without the assumption of equal variance. The unequal variance (heteroscedasticity) does not affect our estimates of the population means, but rather our assessment of whether or differences are statistically significant, in the form of t statistics, p-values and confidence intervals.</p>
</div>
<div id="mann-whitney-u-test" class="section level2">
<h2><span class="header-section-number">6.3</span> Mann-Whitney U test</h2>
<p>If our usual assumptions don’t hold (e.g. normal distributions, or if we’re working with ordinal data) we can use a non-parametric version of these tests instead. When comparing two independent samples, this would be the Mann-Whitney U test.</p>
<p><strong>Mann-Whitney U test:</strong></p>
<p>This tests the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. In other words, if the null hypothesis was rejected, you would infer that values from one population are more likely to be higher or lower than values from another population.</p>
<p>The Man-Whitney U test is a Wilcoxon test but with two samples. It can be run using R’s built-in <a href="https://www.rdocumentation.org/packages/stats/versions/3.5.3/topics/wilcox.test">wilcox.test</a>, this time with the (default) assumption that the observations are not paired.</p>
<p><strong>Equivalent linear model:</strong></p>
<p>Another way to describe the Mann-Whitney U test is as a test of mean ranks. It first ranks all your values for the dependent variable (e.g. income) from high to low, with the smallest rank assigned the smallest value. It then computes the mean rank in each group (e.g. male or female), and then computes the probability than random shuffling of those values between two groups would end up with the mean ranks as far apart as, or further apart, than you observed (see for example <a href="https://stats.stackexchange.com/questions/113334/mann-whitney-test-with-unequal-variances">StackExchange</a> and <a href="https://statistics.laerd.com/premium-sample/mwut/mann-whitney-test-in-spss-2.php">Laerd</a>). If the resulting p-value was sufficiently small, you would infer that the difference in mean ranks between the samples was probably not due to chance, and that the values from one population were higher than those from another.</p>
<p>The equivalent linear model, with a close approximation, is a regression using the rank of the dependent variable:</p>
<p><span class="math inline">\(rank(y_i) = \beta_0 + \beta_1 \cdot x_i \qquad H_0: \beta_0 = 0\)</span></p>
<p>where again <span class="math inline">\(x_i\)</span> is a dummy variable indicating the group to which an observation belongs (in this example, 0 for women and 1 for men). Note that this uses the rank of the dependent variable, and not the signed rank as was the case with matched pairs.</p>
<p><strong>Comparison:</strong></p>
<p>Here is how you would run the Man-Whitney U test and equivalent linear model in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Wilcoxon / Mann-Whitney U test (built-in)</span>
<span class="kw">wilcox.test</span>(y, y2, <span class="dt">paired =</span> <span class="ot">FALSE</span>)

<span class="co"># Equivalent linear model</span>
lm &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">rank</span>(value) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>group_y2, <span class="dt">data =</span> mydata_dummy)  
  lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">digits =</span> <span class="dv">8</span>) <span class="co"># show summary output</span></code></pre></div>
<p>The results are shown below. Both tests have very similar p-values. On this basis, we would not reject the null hypothesis that a value randomly selected from group <code>y</code> was not more likely to be higher or lower than one sampled from <code>y2</code>.</p>
<table>
<caption><span id="tab:unnamed-chunk-35">Table 6.4: </span>Mann-Whitney U and equivalent linear model</caption>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="right">p-value</th>
<th align="left">rank diff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">wilcox.test</td>
<td align="right">0.7907</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">lm (ranks)</td>
<td align="right">0.7896</td>
<td align="left">1.56</td>
</tr>
</tbody>
</table>
<p><strong>Digression - Mann-Whitney U test and medians:</strong></p>
<p>It’s worth noting that, with additional assumptions, the Man-Whitney U test is also a test for different <em>medians</em>.</p>
<p>This requires the assumption that the two samples have an equal shape, and therefore an equal variance. <a href="https://statistics.laerd.com/premium-sample/mwut/mann-whitney-test-in-spss-2.php">Laerd</a> illustrates this concept using the diagram below: on the left, the two samples (men and women) have the same shape, so the Mann-Whitney U test tests for differences in the median score for men and women. On the right, the samples have different shapes, so it is a more general test for whether a randomly-selected woman’s score is higher than a randomly-selected man’s score (without telling us anything about medians).</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-36"></span>
<img src="images/mann_whitney_laerd.png" alt="Man-Whitney U test and sample shapes" width="95%" />
<p class="caption">
Figure 6.2: Man-Whitney U test and sample shapes
</p>
</div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>This can be tested with the Levene’s Test for Equality of Variances.<a href="two-means-independent-samples.html#fnref4">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="one-mean.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="three-or-more-means.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["stat_tests.pdf", "stat_tests.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
